---
title: "Stop! You Are Being Frisked!"
author: "Lauren, Olya, Matt, Cj, & Keyanna"
date: "December 5, 2019"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    code_folding: hide
      
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(rvest)
library(httr)
library(lubridate)
library(plotly)
library(rgdal)
library(sp)
library(sf)
library(leaflet)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```



# Motivation

Terry Stop is a crime-preventing program that has been used by the police around the country for more than 40 years. In New York City this program is known as stop-and-frisk and consists of possible temporary detention and questioning of an individual with possible searching for weapons or other contraband. During Michael Bloomberg’s tenure as a mayor of the City of New York, this program became increasingly aggressive and subsequently turned out to be the hot topic of discussion throughout the nation. In 2011 stop-and-frisk reached almost 700,000 stops. During the same year the New York Civil Liberties Union successfully sued the New York Police Department and forced it to regularly report to public all stop-and-frisk related activities. From the obtained data, it was concluded, that majority of stopped individuals were black and Hispanic men. Bloomberg and then NYC Police Commissioner Raymond W. Kelly, were accused of racial profiling. 

Stop-and-frisk has been proven to be unsuccessful in identifying criminals and recovering illegal weapons. For years Bloomberg argued that there is a causal relationship between stop-and-frisk and crime rates in NYC, in order to rally support for the program. This assumption has been proven to be incorrect by the fact that even after the program was scaled back, crime rates continued to decline in NYC. 
During mayoral election campaign in 2013, public pressure forced Bloomberg to cut back this  practice. 

After Bill de Blasio won mayoral election in 2013, he continued to downsize the program. In 2016 number of stops were less than 2% in comparison to that of 2011, when the stops reached its peak. In spite of expectations, crime prevalence continued to decline even after the program was decreased by 98%.  



# Related Work
New York Civil Liberties Union report “Stop-and-Frisk in the de Blasio era”.

# Initial Questions
*What questions are you trying to answer? How did these questions evolve over the course over the course of the project? What new questions did you consider in the course of your analysis?*

We are interested in determining if there is a predictive nature to this dataset. We also want to describe the scope of the dataset through visualizations of the different demographics present and create a map of stops across the five boroughs. Specifically, we strive to answer the following questions:


* What is the distribution of demographics in the dataset? 
* After being stopped, can demographics, characteristics, and location of stop predict whether or not the individual will be frisked or arrested? 
* What are the trends in stops across different areas of New York City? 

# Data
Our dataset is from the New York Police Department and was obtained through the NYC Open Data resource. It contains data from 12,404 stops that occurred during 2016. The original dataset contained 112 variables, however to narrow our focus, the dataset was reduced down to 45 categorical, binary, and numerical variables that describe each stop and are relevant to the questions at hand. The data cleaning and tidying process recoded variables, implemented understandable variable names, and converted categorical variables to factors and binary variables into ‘0’ and ‘1’ within R. The outcome variables that we are interested in building models for are FRISKED and ARST_MADE. These variables are binary in nature and describe whether the stopped individual was frisked and/or arrested. 


# Exploratory Analysis
*Visualizations, summaries, and exploratory statistical analyses. Justify the steps you took, and show any major changes to you ideas.*

## Loading and tidying the data

To obtain a dataset that could be used in LASSO and modeling logistic regression, several categorical variables with levels that had representation of less than 2% were regrouped into 'other' to ensure that both the testing and training dataset have individuals represented from all categorical levels. This included regrouping levels within the variables build, race, hair color, and eye color.

```{r, message=FALSE}
# Read in data
stop_frisk_df = 
  # Read in data from internet
  GET("https://www1.nyc.gov/assets/nypd/downloads/excel/analysis_and_planning/stop-question-frisk/sqf-2016.csv") %>% 
  content("parsed") %>% 
  
  # Clean and fix names of columns
  janitor::clean_names() %>% 
  rename(
    precinct = pct,
    date_stop = datestop,
    time_stop = timestop,
    stop_in_out = inout,
    obs_time_min = perobs,
    stop_time_min = perstop,
    arst_made = arstmade,
    off_in_unif = offunif,
    hair_col = haircolr,
    eye_col = eyecolor,
    other_feature = othfeatr,
    boro = city
  )  %>% 
  mutate(
    # Combine height columns
    height_inch = ht_feet * 12 + ht_inch,
    # Convert date to proper format
    date_stop = mdy(date_stop),
    # Convert time to proper format
    time_stop = hm(time_stop / 100),
    # Recode to be more informative
    stop_in_out = recode(stop_in_out, "I" = "inside", "O" = "outside"),
    race = recode(
      race, 
      "A" = "other", 
      "B" = "black", 
      "I" = "other",
      "P" = "black-hispanic",
      "Q" = "white-hispanic",
      "W" = "white",
      "U" = "other",
      "Z" = "other"
    ),
    hair_col = recode(
      hair_col,
      "BA" = "bald",
      "BK" = "black",
      "BL" = "blond",
      "BR" = "brown",
      "DY" = "other",
      "FR" = "other",
      "GY" = "other",
      "RA" = "other",
      "SN" = "other",
      "SP" = "other",
      "WH" = "other",
      "XX" = "other",
      "ZZ" = "other",
    ),
    eye_col = recode(
      eye_col,
      "BK" = "black",
      "BL" = "blue",
      "BR" = "brown",
      "DF" = "other",
      "GR" = "other",
      "GY" = "other",
      "HA" = "other",
      "MA" = "other",
      "PK" = "other",
      "VI" = "other",
      "XX" = "other",
      "Z" = "other",      
    ),
    build = recode(
      build,
      "H" = "heavy",
      "M" = "medium",
      "T" = "thin",
      "U" = "other",
      "Z" = "unknown"
    ),
    # change boro columns to lowercase for consistency
    boro = tolower(boro),
    # change character datatypes to numeric
    age = as.numeric(age),
    obs_time_min = as.numeric(obs_time_min),
    stop_time_min = as.numeric(stop_time_min)
  )  %>% 
  # select columns for further analysis
  select(precinct, date_stop, time_stop, stop_in_out, obs_time_min, stop_time_min, arst_made, off_in_unif, frisked, 
         searched, rf_vcrim, rf_othsw, rf_attir:ac_evasv, cs_furtv:cs_other, rf_knowl, sb_hdobj:sb_admis, rf_furt, 
         rf_bulg, sex, race, age, height_inch, weight:build, boro, xcoord, ycoord) %>% 
  # change all columns that have Y/N to 1/0
  mutate_at(vars(arst_made:rf_bulg), funs(recode(., "Y" = "1", "N" = "0"))) %>% 
  # change binary columns to numeric instead of character
  mutate_at(vars(arst_made:rf_bulg), funs(as.numeric(.))) %>% 
  # converts all character variables to factors (this does the same as the for loop)
  mutate_if(is.character, as.factor) %>% 
  # remove the single row of NAs
  filter(!is.na(build))
```

## Demographics 
The 12,404 reported stops in 2016 were spread unevely amongst the different races with black being the leading race over 50%, white-hispanic about 20%, and white, other and black-hispanic being under 10%. Of those 12,404 reported stops 7939 were frisked and among those different races who were frisked is about the same percentage as those who were stop. 

The age range of the reported stops is from ages 1-99. The distribution 

## Logistic Regression Analysis

Goal: To select for models that will best answer the following questions:

 * Among those who were stopped, can we model demographics, location of stop, and reasons for stopping to predict whether the person will be frisked or not?
 * Among those who were stopped, can we model demographics, location of stop, and reasons for stopping to predict whether the person will be arrested or not? 

Methods: 

Only variables that preceded the individual being stopped were used in logistic regression models. Thus, all variables that described reason for frisk or reason for search were omitted. We focused on the characteristics, demographics, location, and reasons for stopping in the model. To build models for ARST_MADE and FRISKED, we evaluated GVIF to verify that there is no multicollinearity present and removed any variables suspected of having high collinearity. Model selection was based on consideration of AIC values, inflated standard errors, and p values. When AIC values did not change between models, ANOVA was used to compare similar models to determine whether the larger or smaller model was significantly better. Above all, we wanted to keep the concept of parsimony in mind when selecting models and minimize overfitting. Finally, the models were evaluated using a training and testing dataset to assess the preditive ability of the model using Area Under the Curve (AUC). 

FRISKED Model: 

Utilizing the methods above, the logistic regression model that was determined to have the best predictive ability included the variables: sex, race, age, height, build, stop inside/outside, officer in uniform, precinct, reason for stop - fits a relevant description, casing a victim or location, furtive movements, violent crime suspected, suspicious bulge, and other. With this model, the predictive power was 0.584. This value is only slightly better than guessing (0.50).
```{r, results='hide', message=FALSE}
set.seed(1)
train = sample_frac(stop_frisk_df, size = 0.8)
test = anti_join(stop_frisk_df, train)

model_1 = glm(frisked ~ sex + race + age + height_inch + weight + hair_col + eye_col + boro + build + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_lkout + cs_cloth + cs_drgtr + cs_furtv + cs_vcrim+ cs_bulge + cs_other, family = binomial, data = train)

car::vif(model_1)
# Based on the GVIF, we will remove boro

model_2 = glm(frisked ~ sex + race + age + height_inch + weight + hair_col + eye_col + build + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_lkout + cs_cloth + cs_drgtr + cs_furtv + cs_vcrim+ cs_bulge + cs_other, family = binomial, data = train)

car::vif(model_2)
# no more collinearity problems

summary(model_2)
# Remove hair and eye color because all categories within them are highly unsignificant, cs_drgtr, cs_lkout

model_3 = glm(frisked ~ sex + race + age + height_inch + weight + build + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_cloth + cs_furtv + cs_vcrim+ cs_bulge + cs_other, family = binomial, data = train)

summary(model_3)
# remove weight, cs_cloth, cs_objcs
model_4 = glm(frisked ~ sex + race + age + height_inch + build + stop_in_out + precinct + off_in_unif + cs_descr + cs_casng + cs_furtv + cs_vcrim+ cs_bulge + cs_other, family = binomial, data = train)

summary(model_4)
anova(model_4, model_3, test = "Chisq")

log_pred = predict(model_4, newdata = test, type = "response")

log_pred = ifelse(log_pred > 0.5, 1, 0)

library(ROCR)
library(Metrics)

pr = prediction(log_pred, test$frisked)
perf = performance(pr, measure = "tpr", x.measure = "fpr")
auc(test$frisked, log_pred)
```


FRISKED AUC Curve
```{r, message=FALSE}
plot(perf)
```


ARST_MADE Model: 

The logistic regression model that was determined to have the best predictive ability included the variables: race, age, weight, stop inside/outside, whether the officer was in uniform, and seven reasons for stop variables. This model only performed slightly better than taking a random guess, with an AUC value of 0.5283.
```{r, results='hide', message=FALSE}
model_5 = glm(arst_made ~ sex + race + age + height_inch + weight + hair_col + eye_col + boro + build + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_lkout + cs_cloth + cs_drgtr + cs_furtv + cs_vcrim+ cs_bulge + cs_other, data = train)

summary(model_5)

car::vif(model_5)

# remove eye color and build, remove boro due to correlation
model_6 = glm(arst_made ~ sex + race + age + height_inch + weight + hair_col + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_lkout + cs_cloth + cs_drgtr + cs_furtv + cs_vcrim+ cs_bulge + cs_other, family = binomial, data = train)

summary(model_6)

# remove height, age
model_7 = glm(arst_made ~ sex + race + weight + hair_col + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_lkout + cs_cloth + cs_drgtr + cs_furtv + cs_vcrim+ cs_bulge + cs_other, family = binomial, data = train)

summary(model_7)

# remove cs_furtv, cs_vcrim, cs_other
model_8 = glm(arst_made ~ sex + race + weight + hair_col + stop_in_out + precinct + off_in_unif + cs_objcs + cs_descr + cs_casng + cs_lkout + cs_cloth + cs_drgtr + cs_bulge, family = binomial, data = train)

summary(model_8)

library(caret)

log_pred = predict(model_8, newdata = test, type = "response")

log_pred = ifelse(log_pred > 0.5, 1, 0)

library(ROCR)
library(Metrics)

pr = prediction(log_pred, test$arst_made)
perf = performance(pr, measure = "tpr", x.measure = "fpr")
auc(test$arst_made, log_pred)
```

ARST_MADE AUC Curve
```{r}
plot(perf)
```


## LASSO Regression

LASSO regression was used to determine if machine learning could build a model that can make better predictions. Observations with missing data was removed, testing and training datasets were created, and cross validation was used to select the best model using the LASSO procedure. A matrix dataset was used to create dummy variables for all categorical variables, resulting in 33 variables. The lasso procedure for the FRISKED model only minimized one variable to zero and kept 32 variables in the model. The AUC value was 0.461, which was less than the value selected from our logistic modeling. LASSO regression for the arrest made model selected 22 of the 33 variables and minimized the others to 0. The resulting AUC value was 0.407, which was significantly worse predictions compared to the logistic model from above. 

```{r, results = 'hide', message=FALSE}
library(glmnet)

set.seed(1)

# getting rid of incomplete observations
stop_frisk_lasso = stop_frisk_df[complete.cases(stop_frisk_df), ]

# keeping only variables we want to use with frisked logistic prediction
stop_frisk_lasso = stop_frisk_lasso %>% select(frisked, sex, race, age, height_inch, weight, hair_col, eye_col, build, stop_in_out, precinct, off_in_unif, cs_objcs, cs_descr, cs_casng, cs_lkout, cs_cloth, cs_drgtr, cs_furtv, cs_vcrim, cs_bulge, cs_other)

# create test and train datasets
train_lasso = sample_frac(stop_frisk_lasso, size = 0.5)
test_lasso = anti_join(stop_frisk_lasso, train_lasso)

# creating x and y
x = model.matrix(frisked ~ ., train_lasso)[,-1]
y = train_lasso$frisked

# lasso fit
lasso_fit = glmnet(x, y, family = "binomial")

# cross validation
lasso_cv = cv.glmnet(x, y, family = "binomial", type = "mse")

lambda_opt = lasso_cv$lambda.min

# visualizing best lambda
broom::tidy(lasso_fit) %>% 
  select(term, lambda, estimate) %>% 
  complete(term, lambda, fill = list(estimate = 0) ) %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = log(lambda, 10), y = estimate, group = term, color = term)) + 
  geom_path() + 
  geom_vline(xintercept = log(lambda_opt, 10), color = "blue", size = 1.2) +
  theme(legend.position = "none")

lasso_fit = glmnet(x, y, lambda = lambda_opt)
lasso_fit %>% broom::tidy()
```


```{r, results='hide', message=FALSE}
#min value of lambda
lambda_min <- lasso_cv$lambda.min
#best value of lambda
lambda_1se <- lasso_cv$lambda.1se
#regression coefficients
coef(lasso_cv, s = lambda_1se)

#get test data
x_test <- model.matrix(frisked ~ ., test_lasso)
x_test = x_test[,-1]

#predict class, type=”class”
lasso_prob <- predict(lasso_cv, newx = x_test, s = lambda_1se, type = "response")

#translate probabilities to predictions
lasso_predict <- rep("Pred No Frisk", nrow(test_lasso))
lasso_predict[lasso_prob > 0.5] <- "Pred Frisk"

auc(test_lasso$frisked, lasso_predict)
```

Confusion Matrix: Predicted Frisked Status vs True Frisked Status
```{r}
#confusion matrix
table(pred = lasso_predict, true = test_lasso$frisked) %>% knitr::kable(col.names = c("No Frisk", "Frisk"))
```

```{r, message=FALSE, results='hide'}
set.seed(1)
# getting rid of incomplete observations
stop_frisk_lasso_arst = stop_frisk_df[complete.cases(stop_frisk_df), ]

# keeping only variables we want to use with frisked logistic prediction
stop_frisk_lasso_arst = stop_frisk_lasso_arst %>% select(arst_made, sex, race, age, height_inch, weight, hair_col, eye_col, build, stop_in_out, precinct, off_in_unif, cs_objcs, cs_descr, cs_casng, cs_lkout, cs_cloth, cs_drgtr, cs_furtv, cs_vcrim, cs_bulge, cs_other)


# create test and train datasets
train_lasso_arst = sample_frac(stop_frisk_lasso_arst, size = 0.5)
test_lasso_arst = anti_join(stop_frisk_lasso_arst, train_lasso_arst)

# creating x and y
x = model.matrix(arst_made ~ ., train_lasso_arst)[,-1]
y = train_lasso_arst$arst_made

# lasso fit
lasso_fit = glmnet(x, y, family = "binomial")

# cross validation
lasso_cv = cv.glmnet(x, y, family = "binomial", type = "mse")

lambda_opt = lasso_cv$lambda.min
```

```{r}
# # visualizing best lambda
broom::tidy(lasso_fit) %>% 
   select(term, lambda, estimate) %>% 
   complete(term, lambda, fill = list(estimate = 0) ) %>% 
   filter(term != "(Intercept)") %>% 
   ggplot(aes(x = log(lambda, 10), y = estimate, group = term, color = term)) + 
   geom_path() + 
   geom_vline(xintercept = log(lambda_opt, 10), color = "blue", size = 1.2) +
   theme(legend.position = "none")
```

```{r, results='hide', message=FALSE}
# coefficients from the optimal model
lasso_fit = glmnet(x, y, lambda = lambda_opt)
lasso_fit %>% broom::tidy()

#min value of lambda
lambda_min <- lasso_cv$lambda.min
#best value of lambda
lambda_1se <- lasso_cv$lambda.1se
#regression coefficients
coef(lasso_cv, s = lambda_1se)

#get test data
x_test <- model.matrix(arst_made ~ ., data = test_lasso_arst)
x_test = x_test[,-1]

#predict class, type=”class”
lasso_prob <- predict(lasso_cv, newx = x_test, s = lambda_1se, type = "response")

#translate probabilities to predictions
lasso_predict <- rep("Predicted No Arrest", nrow(test_lasso_arst))
lasso_predict[lasso_prob > 0.25] <- "Predicted Arrest"

#confusion matrix
table(pred = lasso_predict, true = test_lasso_arst$arst_made)

auc(test_lasso_arst$arst_made, lasso_predict)
```

Confusion Matrix: Predicted Arrested Status vs True Arrested Status
```{r}
#confusion matrix
table(pred = lasso_predict, true = test_lasso_arst$arst_made) %>% knitr::kable(col.names = c("No Arrest", "Arrest"))
```


# Additional Analysis
## Minors
Additional analysis was performed for stopped individuals under age of 18.

14.8% of people who were stopped were underage of 18; out of those 156 were female, 1674 were male and 17 were identified as other. Reasons for stopping minors are consistent with the overall trend in the data set. The most common reasons are "fits a relevant description", "furtive movements" and the "other". In 2016 80% of minors stopped were innocent and 20% were arrested. Out of minors who have been arrested 86% were black, white-hispanic or black-hispanic. 

Majority of stopped minors were innocent:83.5% of white minors, 82.6% of black minors, 78.6% of other race caftegory of minors, 76.3% of white-hispanic minors and 76.2% of black-nispanic minors.

```{r, message - FALSE}
under_18 = stop_frisk_df %>% 
  filter(age<'18') 

under_18 %>%
  count(race) %>% 
  mutate(
    race = fct_reorder(race, -n)) %>% 
  plot_ly(x = ~ race, y = ~ n, type = "bar", color = ~ race) %>% 
  layout(
    title = 'Minors Stopped by Race',
    xaxis = list(
      type = 'category',
      title  = 'Race'), 
    yaxis = list(
      title = 'Count',
      range = c(0, 1100)
    ) 
  )

# percent innocent and arrested amoung minors 
under_18 %>% 
  count(arst_made) %>%
  mutate(
    percent = (n /nrow(under_18)* 100)
  ) %>% 
  knitr::kable(digits = 2)

# Percent innocent minors among each race category
under_18_inn = function(x) {
  stop_frisk_df %>% 
  filter(age < 18,
         race == x) %>% 
  group_by(race, arst_made) %>% 
  count() %>% 
  pivot_wider(
    names_from = arst_made,
    values_from = n) %>% 
  rename(
    innocent = `0`,
    arrested = `1`) %>% 
  mutate(
    percentage = (innocent/(innocent + arrested)) *100)
}

output = map_df(stop_frisk_df$race, under_18_inn) %>% 
  distinct(race, percentage)

output %>% 
  ungroup(race) %>% 
  mutate(
    race = fct_relevel(race, c("white", "black", "other", "white-hispanic")),
    race = recode(race, 
                  "white" = "White",
                  "black" = "Black",
                  "other" = "Other",
                  "white-hispanic" = "White-Hispanic",
                  "black-hispanic" = "Black-Hispanic")
    ) %>% 
plot_ly(x = ~race, y = ~percentage, type = "bar", color = ~race) %>% 
  layout(
    title = 'Percent innocent Minors among each race category',
    xaxis = list(
      type = 'category',
      title  = 'Race'), 
    yaxis = list(
      title = 'Percent innocent, %',
      range = c(0, 100)
    ) 
  )
```


## Trends over time

We also conducted analysis to explore the trends in stops over time and by borough in NYC. We discovered that the number of stops steadily decreased through 2016. Also, most boroughs in NYC have a similar trend and number of stops, except for Staten Island, which had a steady smaller number of stops. Additionally, the frequency of stops is less in the morning (with 7 AM having the smallest number of stops) and higher towards the evening/night. Finally, we looked at the number of stops by the day of the week and discovered that less stops occur on Sunday and Monday than the other days of the week.

```{r, message=FALSE}
# Number of stops per day
stops_per_day =
  stop_frisk_df %>% 
  group_by(date_stop) %>% 
  summarize(
    count = n()
  ) %>% 
  ggplot(aes(x = date_stop, y = count)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(
    title = "Number of stops per day in 2016",
    x = "Date of stop",
    y = "Number of stops"
  )

# Number of stops per month (broken down by boro) 
stops_per_month =
  stop_frisk_df %>% 
  mutate(
    month_stop = month(date_stop),
    boro = str_to_title(boro)
  ) %>%   
  group_by(month_stop, boro) %>% 
  summarize(
    count = n()
  ) %>% 
  ggplot(aes(x = month_stop, y = count, color = boro)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(
    title = "Number of stops per month by borough",
    x = "Month of stop",
    y = "Number of stops",
    color = "Borough"
  ) +
  scale_x_continuous(
    breaks = 1:12,
    labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
  )

# Number of stops per hour over the day
stops_per_hour =
  stop_frisk_df %>% 
  mutate(
    hour_stop = hour(time_stop),
    part_of_day = cut(hour_stop, breaks = c(0, 5, 12, 17, 21, 24), labels = c("Night", "Morning", "Afternoon", "Evening", "Night"), right = FALSE),
    part_of_day = fct_relevel(part_of_day, "Morning", "Afternoon", "Evening")
  ) %>% 
  select(hour_stop, part_of_day) %>% 
  group_by(hour_stop, part_of_day) %>% 
  summarize(
    count = n()
  ) %>% 
  ggplot(aes(x = hour_stop, y = count)) + 
  geom_bar(stat = "Identity", aes(fill = part_of_day)) +
  labs(
    title = "Number of stops per hour over the day",
    x = "Hour of stop",
    y = "Number of stops",
    fill = "Part of day"
  )

# Number of stops per day of week 
stops_per_dow = stop_frisk_df %>% 
  mutate(
    dow_stop = wday(date_stop, label = TRUE)
  ) %>% 
  group_by(dow_stop) %>% 
  summarize(
    count = n()
  ) %>% 
  ggplot(aes(x = dow_stop, y = count)) + 
  geom_bar(stat = "Identity") +
  labs(
    title = "Number of stops per day of week",
    x = "Day of week",
    y = "Number of stops"
  ) +
  theme(legend.position = "none")

(stops_per_month + stops_per_dow) / (stops_per_hour + stops_per_day)
```




# Discussion
*What were you findings? Are they what you expected? What insights into the data can you make?*

The models created for FRISKED and ARST_MADE were not very successful at predicting who would be frisked or arrested. These models were only slightly more sucessful at predicting whether or not the person would be frisked or arrested than taking a guess. While our goal was to develop a predictive model, this points to the fact that officers are not basing their frisk/arrest decisions on characteristics, demographics, and location of the stop. After the tactic came under scrutiny, the NYPD is taking measures to ensure that the policy is non-discriminant, which from our analyses we can see is successful. However, as is described under the demographics analysis section, those that are stopped in the first place tend to be non-white race. 



  


